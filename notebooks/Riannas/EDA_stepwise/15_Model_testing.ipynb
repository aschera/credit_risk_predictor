{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6ec995-2da3-4f18-ba18-1e6bf47007e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,\n",
    "    VotingClassifier, RandomForestRegressor, ExtraTreesClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, SGDClassifier\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    log_loss\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV, KFold, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, StandardScaler\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics, linear_model, neighbors, ensemble, tree\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pickle\n",
    "\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d013332-e9bc-48ab-b42b-dfb437128a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the CSV file with specified data types\n",
    "df = pd.read_csv('final_dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cfe31e-e712-44c3-a49c-45f07a4a7014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manufactured_home_secured_property_type\n",
      "3    53728\n",
      "1     1086\n",
      "2       18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['manufactured_home_secured_property_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935c878b-8ba6-407d-81ea-52e78ffe4312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_taken</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>lien_status</th>\n",
       "      <th>open_end_line_of_credit</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>combined_loan_to_value_ratio</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>total_loan_costs</th>\n",
       "      <th>origination_charges</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>...</th>\n",
       "      <th>applicant_ethnicity_1</th>\n",
       "      <th>co_applicant_ethnicity_1</th>\n",
       "      <th>applicant_race_1</th>\n",
       "      <th>applicant_race_2</th>\n",
       "      <th>co_applicant_race_1</th>\n",
       "      <th>co_applicant_race_2</th>\n",
       "      <th>applicant_sex</th>\n",
       "      <th>co_applicant_sex</th>\n",
       "      <th>applicant_age</th>\n",
       "      <th>co_applicant_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>205000</td>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>155000</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55000</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>345000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_taken  loan_type  lien_status  open_end_line_of_credit  loan_amount  \\\n",
       "0             3          3            1                        2       205000   \n",
       "1             3          2            1                        2       155000   \n",
       "2             3          2            1                        2       125000   \n",
       "3             3          2            1                        2        55000   \n",
       "4             3          1            1                        2       345000   \n",
       "\n",
       "   combined_loan_to_value_ratio  interest_rate  total_loan_costs  \\\n",
       "0                            16            5.0               7.0   \n",
       "1                             7            5.0               7.0   \n",
       "2                             8            5.0               7.0   \n",
       "3                             7            5.0               7.0   \n",
       "4                             1            5.0               7.0   \n",
       "\n",
       "   origination_charges  loan_term  ...  applicant_ethnicity_1  \\\n",
       "0                  1.0        6.0  ...                    2.0   \n",
       "1                  1.0        6.0  ...                    2.0   \n",
       "2                  1.0        6.0  ...                    2.0   \n",
       "3                  1.0        6.0  ...                    2.0   \n",
       "4                  1.0        3.0  ...                    2.0   \n",
       "\n",
       "   co_applicant_ethnicity_1  applicant_race_1  applicant_race_2  \\\n",
       "0                       2.0               5.0               5.0   \n",
       "1                       2.0               5.0               5.0   \n",
       "2                       2.0               5.0               5.0   \n",
       "3                       2.0               3.0               5.0   \n",
       "4                       2.0               5.0               5.0   \n",
       "\n",
       "   co_applicant_race_1  co_applicant_race_2  applicant_sex  co_applicant_sex  \\\n",
       "0                  5.0                  5.0              1                 2   \n",
       "1                  5.0                  5.0              2                 1   \n",
       "2                  5.0                  5.0              1                 2   \n",
       "3                  3.0                  5.0              1                 2   \n",
       "4                  5.0                  5.0              1                 2   \n",
       "\n",
       "   applicant_age  co_applicant_age  \n",
       "0              7                 4  \n",
       "1              3                 3  \n",
       "2              4                 3  \n",
       "3              2                 2  \n",
       "4              2                 2  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690cba4e-d754-4a23-84b8-1a52d424df2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54832 entries, 0 to 54831\n",
      "Data columns (total 33 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   action_taken                              54832 non-null  int64  \n",
      " 1   loan_type                                 54832 non-null  int64  \n",
      " 2   lien_status                               54832 non-null  int64  \n",
      " 3   open_end_line_of_credit                   54832 non-null  int64  \n",
      " 4   loan_amount                               54832 non-null  int64  \n",
      " 5   combined_loan_to_value_ratio              54832 non-null  int64  \n",
      " 6   interest_rate                             54832 non-null  float64\n",
      " 7   total_loan_costs                          54832 non-null  float64\n",
      " 8   origination_charges                       54832 non-null  float64\n",
      " 9   loan_term                                 54832 non-null  float64\n",
      " 10  negative_amortization                     54832 non-null  int64  \n",
      " 11  interest_only_payment                     54832 non-null  int64  \n",
      " 12  balloon_payment                           54832 non-null  int64  \n",
      " 13  other_nonamortizing_features              54832 non-null  int64  \n",
      " 14  property_value                            54832 non-null  float64\n",
      " 15  occupancy_type                            54832 non-null  int64  \n",
      " 16  manufactured_home_secured_property_type   54832 non-null  int64  \n",
      " 17  manufactured_home_land_property_interest  54832 non-null  int64  \n",
      " 18  total_units                               54832 non-null  int64  \n",
      " 19  income                                    54832 non-null  float64\n",
      " 20  debt_to_income_ratio                      54832 non-null  float64\n",
      " 21  applicant_credit_score_type               54832 non-null  int64  \n",
      " 22  co_applicant_credit_score_type            54832 non-null  int64  \n",
      " 23  applicant_ethnicity_1                     54832 non-null  float64\n",
      " 24  co_applicant_ethnicity_1                  54832 non-null  float64\n",
      " 25  applicant_race_1                          54832 non-null  float64\n",
      " 26  applicant_race_2                          54832 non-null  float64\n",
      " 27  co_applicant_race_1                       54832 non-null  float64\n",
      " 28  co_applicant_race_2                       54832 non-null  float64\n",
      " 29  applicant_sex                             54832 non-null  int64  \n",
      " 30  co_applicant_sex                          54832 non-null  int64  \n",
      " 31  applicant_age                             54832 non-null  int64  \n",
      " 32  co_applicant_age                          54832 non-null  int64  \n",
      "dtypes: float64(13), int64(20)\n",
      "memory usage: 13.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0eefb8-540f-4e6f-bdfb-9c0d012d9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c792f0f1-86de-4ee5-ac83-cba459e93efc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_loan_costs\n",
       "7.000000     25773\n",
       "2.000000      4176\n",
       "1.000000      4000\n",
       "3.000000      3346\n",
       "5.000000      2741\n",
       "4.000000      2549\n",
       "6.000000      2532\n",
       "8.000000      1949\n",
       "9.000000      1566\n",
       "10.000000     1515\n",
       "11.000000     1138\n",
       "12.000000     1112\n",
       "13.000000      696\n",
       "14.000000      523\n",
       "15.000000      371\n",
       "16.000000      308\n",
       "17.000000      242\n",
       "18.000000      185\n",
       "6.339297       110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_loan_costs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3987f3fb-2cc4-4aa8-ab8a-91e264524dc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The target 'y' needs to have more than 1 class. Got 1 class instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Apply SMOTE to the selected column with a reduced sampling strategy\u001b[39;00m\n\u001b[0;32m     30\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_min\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Ensure that the resampled data has the same number of rows as the original DataFrame\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_resampled) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(df):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Test\\lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Test\\lib\\site-packages\\imblearn\\base.py:108\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_sampling_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampling_type\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Test\\lib\\site-packages\\imblearn\\utils\\_validation.py:516\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    511\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_type\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAMPLING_KIND\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m     )\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe target \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m needs to have more than 1 class. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y)\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m class instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    519\u001b[0m     )\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sampling_strategy\n",
      "\u001b[1;31mValueError\u001b[0m: The target 'y' needs to have more than 1 class. Got 1 class instead"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# Define the minority classes for each column\n",
    "minority_classes = {\n",
    "    'applicant_sex': [0.2, 1.0, 0.4],\n",
    "    'co_applicant_sex': [0.0, 1.0],\n",
    "    'applicant_race_1': [0.0],\n",
    "    'co_applicant_race_1': [0.0],\n",
    "    'applicant_ethnicity_1': [0.0],\n",
    "    'co_applicant_ethnicity_1': [0.0],\n",
    "}\n",
    "\n",
    "# Create a dictionary to store resampled datasets for each column\n",
    "resampled_datasets = {}\n",
    "\n",
    "# Create a new DataFrame to store the resampled data\n",
    "resampled_df = df.copy()\n",
    "\n",
    "# Iterate through the columns and apply SMOTE to each\n",
    "for column in df.columns:\n",
    "    if column in minority_classes:\n",
    "        # Select the specific column\n",
    "        selected_column = df[column].values.reshape(-1, 1)\n",
    "\n",
    "        # Define y_min based on the minority class for this column\n",
    "        y_min = [1 if value in minority_classes[column] else 0 for value in df[column]]\n",
    "\n",
    "        # Apply SMOTE to the selected column with a reduced sampling strategy\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(selected_column, y_min)\n",
    "\n",
    "        # Ensure that the resampled data has the same number of rows as the original DataFrame\n",
    "        if len(X_resampled) > len(df):\n",
    "            X_resampled = X_resampled[:len(df)]\n",
    "            y_resampled = y_resampled[:len(df)]\n",
    "\n",
    "        # Update the resampled data in the new DataFrame\n",
    "        resampled_df[column] = X_resampled.flatten()\n",
    "\n",
    "# Now, 'resampled_df' contains all 35 columns with the necessary resampling applied to specific columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91934cc3-94b5-4be3-9907-5005edc0cc77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resampled_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83da716-3888-4d28-9b72-d6af36c50294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a list of columns for which you want to plot the distribution\n",
    "columns_to_plot = list(minority_classes.keys())\n",
    "\n",
    "# Calculate the number of plots and rows\n",
    "num_plots = len(columns_to_plot)\n",
    "num_rows = (num_plots // 3) + (num_plots % 3)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, 5 * num_rows))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    # Extract the resampled values for the current column from the resampled_df\n",
    "    values = resampled_df[column]\n",
    "\n",
    "    # Create a histogram plot\n",
    "    g = sns.histplot(values, ax=axes[i], bins=10, kde=True)\n",
    "    g.set_title(f'Distribution of {column}')\n",
    "    g.set_xlabel(\"Value\")\n",
    "    g.set_ylabel(\"Count\")\n",
    "\n",
    "# Hide any empty subplots\n",
    "for i in range(num_plots, num_rows * 3):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b8ef4-d3d4-4f29-990b-3a3d3699e7f0",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83a68b-edea-485b-8ee9-246e4ff6166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resampled_df.drop('action_taken', axis=1)\n",
    "y = resampled_df['action_taken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55bc4e-4dbf-44ed-8aa4-6bbeb6fa4553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split your data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, split the training data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f29ef6-11a0-46c4-9ab0-a33056f66d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_mapping = {i: col for i, col in enumerate(X_train.columns)}\n",
    "column_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5e72a-210f-4b8f-b8dc-64c20fc42f41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = LogisticRegression(penalty='l2', max_iter=1000, C=1.0) \n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_predict = LR.predict(X_train) \n",
    "print(f\"The accuracy for training: {LR.score(X_train, y_train)}\") \n",
    "print(f\"The accuracy for validation: {LR.score(X_val, y_val)}\") \n",
    "print(f\"F1 score for validation: {f1_score(LR.predict(X_val), y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a05f24-fa21-409d-84c9-e0ecc29d9c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresh_ps = np.linspace(.10, 1, 1000)\n",
    "model_val_probs = LR.predict_proba(X_val)[:, 1]\n",
    "\n",
    "f1_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "best_f1_score, best_thresh_p = 0, 0  # Initialize best F1 score and threshold\n",
    "\n",
    "for p in thresh_ps:\n",
    "    model_val_labels = model_val_probs >= p\n",
    "    prec_scores.append(precision_score(y_val, model_val_labels, average='micro'))\n",
    "    rec_scores.append(recall_score(y_val, model_val_labels, average='micro'))\n",
    "    f1 = f1_score(y_val, model_val_labels, average='micro')\n",
    "    f1_scores.append(f1)\n",
    "    acc_scores.append(accuracy_score(y_val, model_val_labels))\n",
    "    \n",
    "    if f1 > best_f1_score:\n",
    "        best_f1_score = f1\n",
    "        best_thresh_p = p\n",
    "\n",
    "# Create subplots with 2 rows and 2 columns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "# Plot F1 score\n",
    "axes[0, 0].plot(thresh_ps, f1_scores, label='F1', color='blue')\n",
    "axes[0, 0].set_title('F1 Score')\n",
    "axes[0, 0].set_xlabel('Threshold')\n",
    "axes[0, 0].set_ylabel('F1 Score')\n",
    "\n",
    "# Plot Precision\n",
    "axes[0, 1].plot(thresh_ps, prec_scores, label='Precision', color='green')\n",
    "axes[0, 1].set_title('Precision')\n",
    "axes[0, 1].set_xlabel('Threshold')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "\n",
    "# Plot Recall\n",
    "axes[1, 0].plot(thresh_ps, rec_scores, label='Recall', color='red')\n",
    "axes[1, 0].set_title('Recall')\n",
    "axes[1, 0].set_xlabel('Threshold')\n",
    "axes[1, 0].set_ylabel('Recall')\n",
    "\n",
    "# Plot Accuracy\n",
    "axes[1, 1].plot(thresh_ps, acc_scores, label='Accuracy', color='purple')\n",
    "axes[1, 1].set_title('Accuracy')\n",
    "axes[1, 1].set_xlabel('Threshold')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "\n",
    "# Add legends to each subplot\n",
    "for ax in axes.flatten():\n",
    "    ax.legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Logistic Regression Model best F1 score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_f1_score, best_thresh_p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1556a3b-a701-4f6c-b861-03335ecf3c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the predicted probabilities for the positive class\n",
    "model_val_probs = LR.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, model_val_probs)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_val, model_val_probs)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29e30e-61bb-48ef-bc56-a7adc3b2acc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict = (LR.predict_proba(X_train)[:, 1] >= 0.65)\n",
    "\n",
    "print(\"Default threshold:\")\n",
    "print(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n",
    "                                                     recall_score(y_train, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10a4ca-b01e-4596-a425-b414ad874e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict = (LR.predict_proba(X_val)[:, 1] >= 0.65)\n",
    "\n",
    "confusion = confusion_matrix(y_val, y_predict)\n",
    "\n",
    "sns.heatmap(confusion , cmap = plt.cm.Blues, annot = True , square = True , fmt = 'd',\n",
    "           xticklabels = ['accept','decline'],\n",
    "           yticklabels = ['accept','decline']);\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('actual');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5c7f0-a0c0-4b84-b366-9202f63a5f77",
   "metadata": {},
   "source": [
    "Conclusion: clearly overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0973a8a-aea5-4358-afb5-a27aa511751f",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33aa72a-4e52-4692-a497-fcaec8bba464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Now, you can calculate the accuracy and F1 score\n",
    "print('The accuracy for training : ', knn.score(X_train, y_train))\n",
    "print('The accuracy for validation: ', knn.score(X_val, y_val))\n",
    "print('F1_score for train: ', f1_score(knn.predict(X_train), y_train))\n",
    "print('F1_score for validation: ', f1_score(knn.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1345765-1ab0-49a4-8e93-9fd3835e5778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the predicted probabilities for the positive class\n",
    "model_val_probs = knn.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, model_val_probs)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_val, model_val_probs)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297cf905-81b2-47aa-934d-e602d7d827d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict = (knn.predict_proba(X_train)[:, 1] >= 0.65)\n",
    "\n",
    "print(\"Default threshold:\")\n",
    "print(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n",
    "                                                     recall_score(y_train, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3d33c-9285-45ea-9bd2-d03d2795bbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict = (knn.predict_proba(X_val)[:, 1] >= 0.65)\n",
    "\n",
    "confusion = confusion_matrix(y_val, y_predict)\n",
    "\n",
    "sns.heatmap(confusion , cmap = plt.cm.Blues, annot = True , square = True , fmt = 'd',\n",
    "           xticklabels = ['accept','decline'],\n",
    "           yticklabels = ['accept','decline']);\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('actual');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfb8bf-4c68-4dcb-a3a5-4cffec3c9381",
   "metadata": {},
   "source": [
    "Conclusion: clearly overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69e9c6-8e71-42b6-ba7e-0e3da5a6ac68",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efa3fa5-b172-433d-aabe-9391ad0e9240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Gaussian = GaussianNB()\n",
    "Gaussian.fit(X_train, y_train)\n",
    "print('The accuracy for training : ',Gaussian.score(X_train,y_train))\n",
    "print('The accuracy for validation: ',Gaussian.score(X_val,y_val))\n",
    "print('f1_score for train: ',f1_score(Gaussian.predict(X_train), y_train))\n",
    "print('f1_score for validation: ',f1_score(Gaussian.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4d28b-7f23-4cdc-b990-4b286adf4356",
   "metadata": {},
   "source": [
    "# Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c0a53-4d44-481f-91e0-d122d3a9ba19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AB_CLF = AdaBoostClassifier(n_estimators=50, random_state=random_state)\n",
    "AB_CLF.fit(X_train , y_train)\n",
    "print('The accuracy for training : ',AB_CLF.score(X_train,y_train))\n",
    "print('The accuracy for validation: ',AB_CLF.score(X_val,y_val))\n",
    "print('f1_score for train: ',f1_score(AB_CLF.predict(X_train), y_train))\n",
    "print('f1_score for validation: ',f1_score(AB_CLF.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afab59d-1ecd-4dc9-aaf7-4d1354c555cd",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857709a-70d5-4f7a-bf53-67597970a961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SG_PIP_CLF = make_pipeline(StandardScaler(),\n",
    "                     SGDClassifier(max_iter=100, tol=1e-3))\n",
    "SG_PIP_CLF.fit(X_train , y_train)\n",
    "print('The accuracy for training : ',SG_PIP_CLF.score(X_train,y_train))\n",
    "print('The accuracy for validation: ',SG_PIP_CLF.score(X_val,y_val))\n",
    "print('f1_score for train: ',f1_score(SG_PIP_CLF.predict(X_train), y_train))\n",
    "print('f1_score for validation: ',f1_score(SG_PIP_CLF.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca4efa-d45a-4e38-9b96-07fd9b5cbc66",
   "metadata": {},
   "source": [
    "# XGBoost (eXtreme Gradient Boosting) - this takes a very long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e572a7-2d56-4b77-a422-0c174c789aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add early stopping\n",
    "early_stopping_rounds = 3\n",
    "\n",
    "xgb_model1 = xgb.XGBClassifier(early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "parameters = {\n",
    "    'nthread': [4],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'learning_rate': [0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.5, 0.7, 0.9],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'n_estimators': [8000, 9000, 10000],\n",
    "    'missing': [-999],\n",
    "    'seed': [1337],\n",
    "    'eval_metric': ['logloss'],\n",
    "}\n",
    "\n",
    "# Use 3-fold cross-validation\n",
    "clf = GridSearchCV(xgb_model1, parameters, n_jobs=3,\n",
    "                   cv=KFold(n_splits=3, shuffle=True, random_state=random_state),\n",
    "                   scoring='neg_log_loss',  \n",
    "                   verbose=4, refit=True)\n",
    "\n",
    "\n",
    "# Implement early stopping\n",
    "eval_set = [(X_val, y_val)]\n",
    "clf.fit(X_train, y_train, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3597480-9224-49e9-8d10-0dc7fe1ef3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86ce0a-f27c-41ab-bf6e-b04b165e47b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your hyperparameters\n",
    "params = {'colsample_bytree': 0.7,\n",
    " 'eval_metric': 'logloss',\n",
    " 'learning_rate': 0.2,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 1,\n",
    " 'missing': -999,\n",
    " 'n_estimators': 8000,\n",
    " 'nthread': 4,\n",
    " 'objective': 'binary:logistic',\n",
    " 'seed': 1337,\n",
    " 'subsample': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01649f-f223-4d1e-96f3-4d5c387c86d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6ec67-8ab8-4973-bc45-8eb8547f31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and monitor early stopping\n",
    "xgb_model1.fit(X_train, y_train, eval_set=eval_set, verbose=True)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predict = (xgb_model1.predict_proba(X_test)[:, 1] >= 0.59)\n",
    "\n",
    "# Calculate precision and recall on the test set\n",
    "precision = precision_score(y_test, y_predict)\n",
    "recall = recall_score(y_test, y_predict)\n",
    "\n",
    "# Print test set results\n",
    "print(\"Test set results:\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Calculate other evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "# Print other evaluation metrics\n",
    "print(\"Test set results:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60f64a-0896-470c-8db3-b9b76d779e81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b05759-906a-47fa-b5f9-edabfacac82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('xgboost_model.pkl', 'wb') as file:\n",
    "    pickle.dump(xgb_model1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af852191-4794-491f-8a3b-f92ca9345c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Assuming xgb_model1 is your trained XGBoost model\n",
    "booster = xgb_model1.get_booster()\n",
    "\n",
    "# Get feature names\n",
    "feature_names = booster.feature_names\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa745a-8af1-4ee2-9aff-ea6195a4480c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming xgb_model1 is your trained XGBoost model\n",
    "xgb.plot_importance(xgb_model1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e843e-44b2-493e-9dfe-f96d55c5f458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you already have y_test and y_predict from your code\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5, linecolor=\"black\", square=True, cbar=False,\n",
    "            xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
    "            yticklabels=[\"True 0\", \"True 1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4548c-fdca-4143-b641-81995dd9b98f",
   "metadata": {},
   "source": [
    "# Make test data for the webapp\n",
    "\n",
    "We create a json file.\n",
    "it contains 5 accepted rows and 5 declined rows.\n",
    "We feed this to the form in our webapp to test predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074be94-bb34-421d-b4d3-90e1b850c9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accepted_counter = 0  # Initialize the accepted counter\n",
    "dummy_data = []  # List to store the dummy data\n",
    "\n",
    "for index, target_value in enumerate(y_test):\n",
    "    if target_value == 1.0 and accepted_counter < 3:\n",
    "        dummy_name = f\"acceptedDummy{accepted_counter + 1}\"\n",
    "        print(index)\n",
    "        dummy_row = X_test.iloc[index].copy()  # Create a copy of the row\n",
    "        dummy_row['action_taken'] = 1.0  # Set the action_taken value to 1.0 for accepted\n",
    "        dummy_data.append((dummy_name, dummy_row))\n",
    "        accepted_counter += 1\n",
    "\n",
    "dummy_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f70158-4255-43c3-93dd-6d71a5898106",
   "metadata": {},
   "source": [
    "## Make a list of a few predictions and mirror them vs true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed8327-8c48-437b-90a8-e28925927e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a49ecd-7a4c-4353-9d33-5431cd1ab440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store predictions and true values\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "def make_predictions(xgb_model1, X_test, y_test, num_predictions=5):\n",
    "    # Make predictions for the test dataset\n",
    "    for _, testX in X_test.iterrows():\n",
    "        yhat = xgb_model1.predict([testX.values])  # Make a one-step prediction\n",
    "        predictions.append(yhat[0])  # Store the prediction\n",
    "\n",
    "    # Make predictions for the true values\n",
    "    for true_value in y_test:\n",
    "        true_values.append(true_value)  # Store the true value\n",
    "\n",
    "    # Return lists of predictions and true values\n",
    "    return predictions[:num_predictions], true_values[:num_predictions]\n",
    "\n",
    "# Example usage:\n",
    "preds, true_vals = make_predictions(xgb_model1, X_test, y_test, num_predictions=5)\n",
    "\n",
    "# Display the results\n",
    "print(\"Predictions:\", preds)\n",
    "print(\"True Values:\", true_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db630319-8558-4232-8e6c-962f6cb300c8",
   "metadata": {},
   "source": [
    "### See which rows are accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325498fb-4361-4054-b1a5-55bb6420446e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with predictions and true values\n",
    "results_df = pd.DataFrame({'Predictions': predictions, 'True_Values': true_values})\n",
    "\n",
    "# Filter rows where Predictions are 1 (accepted)\n",
    "accepted_rows = results_df[results_df['Predictions'] == 1]\n",
    "\n",
    "# Display the accepted rows\n",
    "print(accepted_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78152a-580d-4759-9964-4dc8050faa07",
   "metadata": {},
   "source": [
    "### Pick a specific accepted row and see its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ae3ed-7e27-4ef9-b14b-d5865a7369dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_xgboost = joblib.load('xgboost_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42518c0-b322-4e3d-bd37-7a32716d4bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row = X_test.iloc[7]\n",
    "true_label = y_test.iloc[7]\n",
    "\n",
    "prediction = xgb_model1.predict([row])\n",
    "if prediction == true_label:\n",
    "    print(\"Model prediction is correct.\", true_label)\n",
    "else:\n",
    "    print(\"Model prediction is incorrect.\", true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f40608-08c6-427a-b101-5e78fd6aa9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row = X_test.iloc[7]\n",
    "true_label = y_test.iloc[7]\n",
    "\n",
    "prediction = model_xgboost.predict([row])\n",
    "if prediction == true_label:\n",
    "    print(\"Model prediction is correct.\", true_label)\n",
    "else:\n",
    "    print(\"Model prediction is incorrect.\", true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16ef39-53cc-44b2-afa4-dac2c2182eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row = X_test.iloc[147]\n",
    "print(row)\n",
    "true_label = y_test.iloc[147]\n",
    "\n",
    "prediction = xgb_model1.predict([row])\n",
    "if prediction == true_label:\n",
    "    print(\"Model prediction is correct.\", true_label)\n",
    "else:\n",
    "    print(\"Model prediction is incorrect.\", true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da2753-7190-4b08-939a-629ba4ebc02f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row = X_test.iloc[147]\n",
    "true_label = y_test.iloc[147]\n",
    "\n",
    "prediction = model_xgboost.predict([row])\n",
    "if prediction == true_label:\n",
    "    print(\"Model prediction is correct.\", true_label)\n",
    "else:\n",
    "    print(\"Model prediction is incorrect.\", true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe632f0c-c533-4408-8778-6df70f51875c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure that data_values has the correct format and values\n",
    "data_values = X_test.iloc[6]  # accept: 0,3,6\n",
    "data_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b51a2-c5b2-4783-95f3-3c77e7fc80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problematic prediction\n",
    "prediction2 = model_xgboost.predict([data_values])\n",
    "print(prediction2)  # This should be 1 if data_values now match the expected format and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88506df4-612c-4097-b57e-45c4935d28e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row1 = X_test.iloc[147]\n",
    "np.save('row1.npy', row1)\n",
    "row1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9914a-5b89-4641-a683-76088e93c643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correct prediction\n",
    "prediction1 = model_xgboost.predict([row1])\n",
    "print(prediction1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443593f-149e-44d9-b1a8-c959359f2a7e",
   "metadata": {},
   "source": [
    "# Pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9d9ed-f1c4-4208-b845-9f388b30e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = linear_model.LogisticRegression(solver=\"lbfgs\", random_state=random_state)\n",
    "dt_model = tree.DecisionTreeClassifier(max_depth=8)\n",
    "ADA_model = AdaBoostClassifier(n_estimators=50, random_state=random_state)\n",
    "SGD_model = make_pipeline(StandardScaler(),\n",
    "                     SGDClassifier(max_iter=100, tol=1e-3))\n",
    "\n",
    "models = [\"lr_model\",\"dt_model\",\"ADA_model\",\"SGD_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331aef4-51af-435c-a696-9df2c057e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "    \n",
    "    curr_model = eval(model_name)\n",
    "    \n",
    "    curr_model.fit(X_train, y_train)\n",
    "    \n",
    "    with open(f\"{model_name}.pickle\", \"wb\") as pfile:\n",
    "        pickle.dump(curr_model, pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e5c23-c225-4f3f-affa-fc389624aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"lr_model\",\"dt_model\",\"ADA_model\",\"SGD_model\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "    with open(f\"{model_name}.pickle\", \"rb\") as pfile:\n",
    "        exec(f\"{model_name} = pickle.load(pfile)\")\n",
    "\n",
    "model_vars = [eval(n) for n in model_names]\n",
    "model_list = list(zip(model_names, model_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad9f28-9e8c-4e0d-81e4-f1cc3e83df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    curr_model = eval(model_name)\n",
    "    print(f'{model_name} score: {curr_model.score(X_train, y_train)}')\n",
    "    print(f'{model_name} score: {curr_model.score(X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbe423-2382-48c6-b88f-807fdb7cbed4",
   "metadata": {},
   "source": [
    "# voting classifer (HARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2b22b-aff0-49fe-80da-4c41f43bf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='hard', #<-- sklearn calls this hard voting\n",
    "                                    n_jobs=-1)\n",
    "voting_classifer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc607988-b88d-4924-b25b-f5b9d2c2b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_classifer.predict(X_train)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f3620-f18d-43bb-8b3a-9a4d5ca6daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_classifer.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf93e0-46ae-4adb-9c25-bc3c817a8203",
   "metadata": {},
   "source": [
    "# Compare all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6353f336-9876-42c5-9c64-28e7011078bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example model and prediction data\n",
    "models = ['LR', 'knn', 'Ada Boost', 'Gaussian', 'Stochastic Gradient Descent', 'xgb_model1', 'Decision Tree', 'SGD_model', 'voting_classifier']\n",
    "y_pred1 = LR.predict(X_val)\n",
    "y_pred2 = knn.predict(X_val)\n",
    "y_pred3 = AB_CLF.predict(X_val)\n",
    "y_pred4 = Gaussian.predict(X_val)\n",
    "y_pred5 = SG_PIP_CLF.predict(X_val)\n",
    "y_pred6 = xgb_model1.predict(X_val)\n",
    "y_pred7 = dt_model.predict(X_val)\n",
    "y_pred8 = SGD_model.predict(X_val)\n",
    "y_pred9 = voting_classifer.predict(X_val)  \n",
    " \n",
    "\n",
    "y_true = y_val  # True labels\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "metrics = {\n",
    "    'Accuracy': [accuracy_score(y_true, y_pred1), accuracy_score(y_true, y_pred2), accuracy_score(y_true, y_pred3),\n",
    "                 accuracy_score(y_true, y_pred4), accuracy_score(y_true, y_pred5), accuracy_score(y_true, y_pred6),\n",
    "                 accuracy_score(y_true, y_pred7), accuracy_score(y_true, y_pred8), accuracy_score(y_true, y_pred9)],\n",
    "    \n",
    "    'Precision': [precision_score(y_true, y_pred1), precision_score(y_true, y_pred2), precision_score(y_true, y_pred3),\n",
    "                  precision_score(y_true, y_pred4), precision_score(y_true, y_pred5), precision_score(y_true, y_pred6),\n",
    "                  precision_score(y_true, y_pred7), precision_score(y_true, y_pred8), precision_score(y_true, y_pred9)],\n",
    "    \n",
    "    'Recall': [recall_score(y_true, y_pred1), recall_score(y_true, y_pred2), recall_score(y_true, y_pred3),\n",
    "               recall_score(y_true, y_pred4), recall_score(y_true, y_pred5), recall_score(y_true, y_pred6),\n",
    "               recall_score(y_true, y_pred7), recall_score(y_true, y_pred8), recall_score(y_true, y_pred9)],\n",
    "    \n",
    "    'F1 Score': [f1_score(y_true, y_pred1), f1_score(y_true, y_pred2), f1_score(y_true, y_pred3),\n",
    "                 f1_score(y_true, y_pred4), f1_score(y_true, y_pred5), f1_score(y_true, y_pred6),\n",
    "                 f1_score(y_true, y_pred7), f1_score(y_true, y_pred8), f1_score(y_true, y_pred9)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(metrics, index=models)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08378c0d-8765-4e04-8f8e-cc973670428b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
