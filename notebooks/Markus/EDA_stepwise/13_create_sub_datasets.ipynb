{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f95f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "     -------------------------------------- 235.6/235.6 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\marku\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.9.1)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     -------------------------------------- 302.2/302.2 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\marku\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marku\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\marku\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.24.3)\n",
      "Installing collected packages: joblib, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.11.0 imblearn-0.0 joblib-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236fe6aa-a953-40d2-830b-d6a8db58d7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import chi2_contingency\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'  # Set to the number of CPU cores you want to use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948cb308-612a-4da1-98c0-736da467816f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load dataset 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a59209-78cf-4057-853f-b81f2fd701a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('12_removed_all_nan_with_mean.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac230a67-7192-4ee7-a1f6-bbe1fa3f771e",
   "metadata": {},
   "source": [
    "# Generate Sub-Datasets: \n",
    "For each sensitive attribute, create sub-datasets by grouping the data based on the different sensitive options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4a32da-23a9-4e28-8266-6a2074684532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into \"males\" and \"females\" and \"joint\"\n",
    "males = df[df['applicant_sex'] == 1] \n",
    "females = df[df['applicant_sex'] == 2]  \n",
    "joint = df[df['applicant_sex'] == 6]  \n",
    "\n",
    "# Create sub-datasets for males and females\n",
    "sub_datasets = {\n",
    "    \"Males\": males,\n",
    "    \"Females\": females,\n",
    "    \"Joint\": joint\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5879b92-5b7f-4c1e-a5c5-16a2a8a4be92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0000    106193\n",
       "4.9095     26160\n",
       "3.0000      5033\n",
       "Name: applicant_race_1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['applicant_race_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af0a2b9-f534-461d-9650-56c68a5a2021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Split the 'Males' dataset based on 'applicant_race_1'\n",
    "males_white = males[males['applicant_race_1'] == 5]\n",
    "males_black = males[males['applicant_race_1'] == 3]\n",
    "\n",
    "# Split the 'Females' dataset based on 'applicant_race_1'\n",
    "females_white = females[females['applicant_race_1'] == 5]\n",
    "females_black = females[females['applicant_race_1'] == 3]\n",
    "\n",
    "# Split the 'Joint' dataset based on 'applicant_race_1'\n",
    "joint_white = joint[joint['applicant_race_1'] == 5]\n",
    "joint_black = joint[joint['applicant_race_1'] == 3]\n",
    "\n",
    "# Create sub-datasets for the resulting combinations\n",
    "sub_datasets = {\n",
    "    \"Males White\": males_white,\n",
    "    \"Males Black\": males_black,\n",
    "    \"Females White\": females_white,\n",
    "    \"Females Black\": females_black,\n",
    "    \"Joint White\": joint_white,\n",
    "    \"Joint Black\": joint_black\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec4f6cae-6d69-4531-ad2c-35ab737924b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the 'Males White' dataset based on 'applicant_ethnicity_1'\n",
    "males_white_latino = males_white[males_white['applicant_ethnicity_1'] == 1.000000]\n",
    "males_white_not_latino = males_white[males_white['applicant_ethnicity_1'] == 2.000000]\n",
    "\n",
    "# Split the 'Males Black' dataset based on 'applicant_ethnicity_1'\n",
    "males_black_latino = males_black[males_black['applicant_ethnicity_1'] == 1.000000]\n",
    "males_black_not_latino = males_black[males_black['applicant_ethnicity_1'] == 2.000000]\n",
    "\n",
    "# Split the 'Females White' dataset based on 'applicant_ethnicity_1'\n",
    "females_white_latino = females_white[females_white['applicant_ethnicity_1'] == 1.000000]\n",
    "females_white_not_latino = females_white[females_white['applicant_ethnicity_1'] == 2.000000]\n",
    "\n",
    "# Split the 'Females Black' dataset based on 'applicant_ethnicity_1'\n",
    "females_black_latino = females_black[females_black['applicant_ethnicity_1'] == 1.000000]\n",
    "females_black_not_latino = females_black[females_black['applicant_ethnicity_1'] == 2.000000]\n",
    "\n",
    "# Split the 'Joint White' dataset based on 'applicant_ethnicity_1'\n",
    "joint_white_latino = joint_white[joint_white['applicant_ethnicity_1'] == 1.000000]\n",
    "joint_white_not_latino = joint_white[joint_white['applicant_ethnicity_1'] == 2.000000]\n",
    "\n",
    "# Split the 'Joint Black' dataset based on 'applicant_ethnicity_1'\n",
    "joint_black_latino = joint_black[joint_black['applicant_ethnicity_1'] == 1.000000]\n",
    "joint_black_not_latino = joint_black[joint_black['applicant_ethnicity_1'] == 2.000000]\n",
    "\n",
    "# Create sub-datasets for the resulting combinations\n",
    "sub_datasets = {\n",
    "    \"Males White Latino\": males_white_latino,\n",
    "    \"Males White Not Latino\": males_white_not_latino,\n",
    "    \"Males Black Latino\": males_black_latino,\n",
    "    \"Males Black Not Latino\": males_black_not_latino,\n",
    "    \"Females White Latino\": females_white_latino,\n",
    "    \"Females White Not Latino\": females_white_not_latino,\n",
    "    \"Females Black Latino\": females_black_latino,\n",
    "    \"Females Black Not Latino\": females_black_not_latino,\n",
    "    \"Joint White Latino\": joint_white_latino,\n",
    "    \"Joint White Not Latino\": joint_white_not_latino,\n",
    "    \"Joint Black Latino\": joint_black_latino,\n",
    "    \"Joint Black Not Latino\": joint_black_not_latino\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af902abf-640b-4c2b-9120-d90b60d6bb6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subset Name</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Males White Latino</td>\n",
       "      <td>6617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Males White Not Latino</td>\n",
       "      <td>69273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Males Black Latino</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Males Black Not Latino</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Females White Latino</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Females White Not Latino</td>\n",
       "      <td>24508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Females Black Latino</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Females Black Not Latino</td>\n",
       "      <td>1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Joint White Latino</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joint White Not Latino</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Joint Black Latino</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Joint Black Not Latino</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Subset Name   Size\n",
       "0         Males White Latino   6617\n",
       "1     Males White Not Latino  69273\n",
       "2         Males Black Latino     91\n",
       "3     Males Black Not Latino   2992\n",
       "4       Females White Latino   2689\n",
       "5   Females White Not Latino  24508\n",
       "6       Females Black Latino     51\n",
       "7   Females Black Not Latino   1584\n",
       "8         Joint White Latino     10\n",
       "9     Joint White Not Latino     32\n",
       "10        Joint Black Latino      0\n",
       "11    Joint Black Not Latino      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to store the sizes of the subsets\n",
    "subset_sizes = []\n",
    "\n",
    "# Iterate through the sub-datasets in your dictionary and calculate the size\n",
    "for sub_dataset_name, sub_dataset in sub_datasets.items():\n",
    "    subset_size = len(sub_dataset)\n",
    "    subset_sizes.append({'Subset Name': sub_dataset_name, 'Size': subset_size})\n",
    "\n",
    "# Create a DataFrame from the list of subset sizes\n",
    "subset_sizes_df = pd.DataFrame(subset_sizes)\n",
    "\n",
    "# Print the subset sizes table\n",
    "subset_sizes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b8448-8c2c-478b-8842-e9fbd6f0bbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee72cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
