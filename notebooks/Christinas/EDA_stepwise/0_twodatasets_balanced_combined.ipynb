{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3b5001-0730-4c24-8b85-6ec45a56f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842dc75b-3f3f-473a-b09d-a63fbb2449c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL to the dataset\n",
    "url = 'https://s3.amazonaws.com/cfpb-hmda-public/prod/three-year-data/2019/2019_public_lar_three_year_csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f8c0ae-5149-4c11-ba3f-8893e75c53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names we want to read:\n",
    "columns_to_read = [\n",
    "'loan_type',\n",
    "'loan_amount',\n",
    "'action_taken',\n",
    "'occupancy_type',\n",
    "'census_tract',\n",
    "'applicant_ethnicity_1',\n",
    "'co_applicant_ethnicity_1',\n",
    "'applicant_race_1',\n",
    "'co_applicant_race_1',\n",
    "'applicant_sex',\n",
    "'co_applicant_sex',\n",
    "'applicant_age',\n",
    "'co_applicant_age',\n",
    "'income',\n",
    "'lien_status',\n",
    "'applicant_credit_score_type',\n",
    "'co_applicant_credit_score_type',\n",
    "'origination_charges',\n",
    "'interest_rate',\n",
    "'debt_to_income_ratio',\n",
    "'combined_loan_to_value_ratio',\n",
    "'loan_term',\n",
    "'property_value',\n",
    "'manufactured_home_secured_property_type',\n",
    "'total_units',\n",
    "'aus_1',\n",
    "'reverse_mortgage',\n",
    "'open_end_line_of_credit',\n",
    "'manufactured_home_land_property_interest',\n",
    "'total_loan_costs',\n",
    "'negative_amortization',\n",
    "'interest_only_payment',\n",
    "'balloon_payment',\n",
    "'other_nonamortizing_features',\n",
    "    \n",
    "'co_applicant_race_2', # Need those for the EDA in '3', remove later.\n",
    "'applicant_race_2'  # Need those for the EDA in '3', remove later.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5ce784-0989-4b74-9bb2-0936f4b6fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('loan_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0adb1718-ceb3-419d-a907-430abb2737cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nimport pandas as pd\\nimport sqlite3\\n\\n# Define your table name\\ntable_name = 'original_data'\\n\\n# Number of rows to load in each batch\\nbatch_size = 10000\\n\\n# Define the filtering condition for 'action_taken' equal to 1\\ncondition_action_1 = lambda x: x == 1\\n\\n# Define the filtering condition for 'action_taken' equal to 3\\ncondition_action_3 = lambda x: x == 3\\n\\n# Initialize counters for each 'action_taken' value\\ncount_action_1 = 0\\ncount_action_3 = 0\\n\\n# Set the desired range of rows for each category\\ndesired_range = (9000, 11000)\\n\\n# Initialize an empty DataFrame to accumulate filtered data\\nfiltered_data = pd.DataFrame()\\n\\n# Keep querying and loading until you reach the desired range\\nwhile True:\\n    chunk = pd.read_csv(url, nrows=batch_size)\\n\\n    if chunk.empty:\\n        break\\n\\n    # Apply filtering conditions to select rows with 'action_taken' equal to 1 or 3\\n    filtered_chunk_action_1 = chunk[chunk['action_taken'].apply(condition_action_1)]\\n    filtered_chunk_action_3 = chunk[chunk['action_taken'].apply(condition_action_3)]\\n\\n    # Update the counters for each 'action_taken' value\\n    count_action_1 += len(filtered_chunk_action_1)\\n    count_action_3 += len(filtered_chunk_action_3)\\n\\n    # Concatenate the filtered dataframes for 'action_taken' values 1 and 3\\n    filtered_chunk = pd.concat([filtered_chunk_action_1, filtered_chunk_action_3])\\n\\n    # Accumulate the data into the filtered_data DataFrame\\n    filtered_data = pd.concat([filtered_data, filtered_chunk])\\n\\n    # Check if you've reached the desired range for both categories\\n    if count_action_1 >= desired_range[0] and count_action_1 <= desired_range[1] and        count_action_3 >= desired_range[0] and count_action_3 <= desired_range[1]:\\n        break\\n\\n# Truncate the accumulated data to fit within the desired range\\nfiltered_data = filtered_data.head(desired_range[1])\\n\\n# Initialize SQLite connection and load the data\\nconn = sqlite3.connect('your_database.db')\\nfiltered_data.to_sql(table_name, conn, if_exists='replace', index=False)\\nconn.close()\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Define your table name\n",
    "table_name = 'original_data'\n",
    "\n",
    "# Number of rows to load in each batch\n",
    "batch_size = 10000\n",
    "\n",
    "# Define the filtering condition for 'action_taken' equal to 1\n",
    "condition_action_1 = lambda x: x == 1\n",
    "\n",
    "# Define the filtering condition for 'action_taken' equal to 3\n",
    "condition_action_3 = lambda x: x == 3\n",
    "\n",
    "# Initialize counters for each 'action_taken' value\n",
    "count_action_1 = 0\n",
    "count_action_3 = 0\n",
    "\n",
    "# Set the desired range of rows for each category\n",
    "desired_range = (9000, 11000)\n",
    "\n",
    "# Initialize an empty DataFrame to accumulate filtered data\n",
    "filtered_data = pd.DataFrame()\n",
    "\n",
    "# Keep querying and loading until you reach the desired range\n",
    "while True:\n",
    "    chunk = pd.read_csv(url, nrows=batch_size)\n",
    "\n",
    "    if chunk.empty:\n",
    "        break\n",
    "\n",
    "    # Apply filtering conditions to select rows with 'action_taken' equal to 1 or 3\n",
    "    filtered_chunk_action_1 = chunk[chunk['action_taken'].apply(condition_action_1)]\n",
    "    filtered_chunk_action_3 = chunk[chunk['action_taken'].apply(condition_action_3)]\n",
    "\n",
    "    # Update the counters for each 'action_taken' value\n",
    "    count_action_1 += len(filtered_chunk_action_1)\n",
    "    count_action_3 += len(filtered_chunk_action_3)\n",
    "\n",
    "    # Concatenate the filtered dataframes for 'action_taken' values 1 and 3\n",
    "    filtered_chunk = pd.concat([filtered_chunk_action_1, filtered_chunk_action_3])\n",
    "\n",
    "    # Accumulate the data into the filtered_data DataFrame\n",
    "    filtered_data = pd.concat([filtered_data, filtered_chunk])\n",
    "\n",
    "    # Check if you've reached the desired range for both categories\n",
    "    if count_action_1 >= desired_range[0] and count_action_1 <= desired_range[1] and \\\n",
    "       count_action_3 >= desired_range[0] and count_action_3 <= desired_range[1]:\n",
    "        break\n",
    "\n",
    "# Truncate the accumulated data to fit within the desired range\n",
    "filtered_data = filtered_data.head(desired_range[1])\n",
    "\n",
    "# Initialize SQLite connection and load the data\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "filtered_data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec433d1-92a8-418e-b713-0a1ef678fe2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n",
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n",
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n",
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n",
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n",
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n",
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n",
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n",
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_9232\\2004898266.py:33: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chunk = pd.read_csv(url, nrows=batch_size)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Define your table name\n",
    "table_name = 'original_data'\n",
    "\n",
    "# Number of rows to load in each batch\n",
    "batch_size = 500000\n",
    "\n",
    "# Define the filtering condition for 'action_taken' equal to 1\n",
    "condition_action_1 = lambda x: x == 1\n",
    "\n",
    "# Define the filtering condition for 'action_taken' equal to 3\n",
    "condition_action_3 = lambda x: x == 3\n",
    "\n",
    "# Initialize an empty DataFrame to accumulate filtered data\n",
    "filtered_data = pd.DataFrame()\n",
    "\n",
    "# Set the number of iterations\n",
    "num_iterations = 3\n",
    "\n",
    "# Establish a SQLite connection\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "\n",
    "# Iterate through batches\n",
    "for iteration in range(num_iterations):\n",
    "    # Reset counters for each iteration\n",
    "    count_action_1 = 0\n",
    "    count_action_3 = 0\n",
    "    \n",
    "    # Keep querying and loading until you reach the desired range\n",
    "    while True:\n",
    "        chunk = pd.read_csv(url, nrows=batch_size)\n",
    "    \n",
    "        if chunk.empty:\n",
    "            break\n",
    "    \n",
    "        # Apply filtering conditions to select rows with 'action_taken' equal to 1 or 3\n",
    "        filtered_chunk_action_1 = chunk[chunk['action_taken'].apply(condition_action_1)]\n",
    "        filtered_chunk_action_3 = chunk[chunk['action_taken'].apply(condition_action_3)]\n",
    "    \n",
    "        # Update the counters for each 'action_taken' value\n",
    "        count_action_1 += len(filtered_chunk_action_1)\n",
    "        count_action_3 += len(filtered_chunk_action_3)\n",
    "    \n",
    "        # Concatenate the filtered dataframes for 'action_taken' values 1 and 3\n",
    "        filtered_chunk = pd.concat([filtered_chunk_action_1, filtered_chunk_action_3])\n",
    "    \n",
    "        # Accumulate the data into the filtered_data DataFrame\n",
    "        filtered_data = pd.concat([filtered_data, filtered_chunk])\n",
    "    \n",
    "        # Check if you've reached the desired range for both categories\n",
    "        if count_action_1 >= batch_size and count_action_3 >= batch_size:\n",
    "            break\n",
    "    \n",
    "    # Check for duplicates based on primary key and insert new rows\n",
    "    filtered_data.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "    \n",
    "    # Clear the filtered_data DataFrame for the next iteration\n",
    "    filtered_data = pd.DataFrame()\n",
    "\n",
    "# Close the SQLite connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce5a8d-a679-4b63-808e-7bbcf463ef23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('loan_database.db')\n",
    "\n",
    "# Specify the name of the table you want to load\n",
    "table_name = 'original_data'\n",
    "\n",
    "# Query to select all rows from the table\n",
    "query = f'SELECT * FROM {table_name}'\n",
    "\n",
    "# Load the data into a Pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Now df contains your data as a Pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2f4b2-07b6-4596-8d41-a6d4f626c25c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['action_taken'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd74bf8-be63-439a-b077-f8eebbfcaa84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5ead6-b7f7-4bfd-94eb-29ef71d30779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
